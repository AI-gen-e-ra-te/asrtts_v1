import os
from faster_whisper import WhisperModel

# æ¨¡åž‹å¤§å°ï¼šbase, small, medium, large-v3
# å»ºè®®å…ˆç”¨ base æµ‹è¯•ï¼Œé€Ÿåº¦å¿«
MODEL_SIZE = "base" 
device = "cuda" if os.environ.get("CUDA_VISIBLE_DEVICES") else "cpu"

print(f"ðŸ”„ Loading Whisper model ({MODEL_SIZE}) on {device}...")
try:
    # compute_type="int8" å¯ä»¥åŠ é€Ÿä¸”çœæ˜¾å­˜
    model = WhisperModel(MODEL_SIZE, device=device, compute_type="int8")
    print("âœ… Whisper model loaded.")
except Exception as e:
    print(f"âŒ Failed to load Whisper: {e}")
    model = None

def transcribe_audio(file_path: str) -> str:
    if not model:
        return "Error: ASR model not loaded."
    
    segments, info = model.transcribe(file_path, beam_size=5, language="zh")
    
    text = ""
    for segment in segments:
        text += segment.text
    
    return text.strip()